{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Classification\"\n",
        "author: \"Mehran Islam\"\n",
        "date: \"2023-12-07\"\n",
        "categories: [code, analysis]\n",
        "image: \"image.jpg\"\n",
        "---"
      ],
      "id": "c92d8dee"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Classification Post**\n",
        "\n",
        "Import the required libraries\n"
      ],
      "id": "f113c5cb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd"
      ],
      "id": "1a1b41e5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as pl\n",
        "import seaborn as sns"
      ],
      "id": "b15d8a74",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read data from file and identify null values\n"
      ],
      "id": "b0bf56d8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data=pd.read_csv('athlete_events.csv', index_col=\"ID\")"
      ],
      "id": "de7defb3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```{data.apply(pd.isnull).sum()/data.shape[0]}\n",
        "```\n"
      ],
      "id": "a9624e6d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "athletes= data[[\"Team\",\"Sex\", \"Season\",\"Sport\",\"Medal\"]].copy()\n",
        "\n",
        "#converting into column\n",
        "athletes.columns = [\"country\",\"sex\",\"season\", \"sport\",\"medal\"]\n",
        "\n",
        "athletes"
      ],
      "id": "0ae34ac5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "athletes.apply(pd.isnull).sum()/athletes.shape[0]"
      ],
      "id": "9ae8135f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "athletes = athletes[athletes['medal'].isin(['Gold', 'Silver', 'Bronze'])].dropna(subset=['medal'])"
      ],
      "id": "72116618",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "athletes"
      ],
      "id": "0dd1d646",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# here we see a high percentage of null values in medal because only some of the athletes win the medal\n",
        "\n",
        "# Create a new DataFrame with the converted 'target' column\n",
        "new_athletes = athletes.copy()  # Make a copy to avoid modifying the original DataFrame\n",
        "\n",
        "# Convert the 'medal' column to 'target' based on the medal values\n",
        "new_athletes['target'] = new_athletes['medal'].apply(lambda x: 'gold' if x =='Gold' else 'no gold')"
      ],
      "id": "38d3cb7f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "new_athletes"
      ],
      "id": "75509dd1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#I just want to include four sports in which US generally do good\n",
        "\n",
        "selected_sports = ['Swimming']\n",
        "\n",
        "recent_athletes = new_athletes[new_athletes['sport'].isin(selected_sports)]"
      ],
      "id": "64893d2a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "recent_athletes.apply(pd.isnull).sum()\n",
        "recent_athletes"
      ],
      "id": "1ad2a4b4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#lets drop silver medals and gold medals because we are only interested in Gold medals\n",
        "\n",
        "#athletes = athletes[athletes['medal'] == 'Gold'].dropna(subset=['medal'])"
      ],
      "id": "2f369df6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create a new DataFrame with the converted columns\n",
        "players = recent_athletes.copy()  # Make a copy to avoid modifying the original DataFrame\n",
        "\n",
        "# Convert the 'country' column to numerical values\n",
        "players['country'] = (recent_athletes['country'] == 'United States').astype(int)\n",
        "\n",
        "# Convert the 'sex' column to numerical values\n",
        "players['sex'] = (recent_athletes['sex'] == 'M').astype(int)\n",
        "\n",
        "\n",
        "# Convert the 'season' column to numerical values\n",
        "players['season'] = (recent_athletes['season'] == 'Summer').astype(int)\n",
        "\n",
        "# Convert the 'sport' column to numerical values\n",
        "players['sport'] = (recent_athletes['sport'] == 'Swimming').astype(int)"
      ],
      "id": "6f05a06b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#since we are only interested in swimming data let's drop others\n",
        "\n",
        "#athletes = athletes[athletes['sport'] == 'Swimming'].dropna(subset=['sport'])"
      ],
      "id": "74cd538c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "players"
      ],
      "id": "d137e45f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Split the data into features (X) and the target variable (y)\n",
        "# to preapre data for ML ready\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = players[['country','sport', 'sex']]\n",
        "y = players['target']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
        "\n",
        "players"
      ],
      "id": "d94e879a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_test.shape"
      ],
      "id": "c5719a2a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.countplot(data=players, x='target')\n",
        "pl.title('Distribution of Target')\n",
        "pl.show()"
      ],
      "id": "986b85a6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# to train the naive model as out target is to use naive bayes model\n",
        "\n",
        "# we use gaussian naive bayes\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Create a Gaussian Naive Bayes model\n",
        "nb_model = GaussianNB()\n",
        "\n",
        "# Train the model on the training data\n",
        "nb_model.fit(X_train, y_train)"
      ],
      "id": "67ea8ffc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# now evaluating the model \n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = nb_model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\\n\", report)"
      ],
      "id": "e017986f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming you have already trained your Naive Bayes model (nb_model) and split your data into training (X_train, y_train) and testing (X_test, y_test) sets.\n",
        "\n",
        "# Example data (replace with your actual data)\n",
        "# X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "# nb_model = MultinomialNB()\n",
        "# nb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = nb_model.predict(X_test)\n",
        "\n",
        "# Create a confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Create a heatmap using seaborn\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "id": "7f2e22bd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Assuming you have the classification report stored in the 'report' variable\n",
        "report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "# Convert the classification report to a DataFrame for easier plotting\n",
        "players_report = pd.DataFrame(report).transpose()\n",
        "\n",
        "# Create a horizontal bar chart using Seaborn\n",
        "pl.figure(figsize=(8, 4))\n",
        "sns.set(style=\"whitegrid\")\n",
        "sns.set_palette(\"pastel\")\n",
        "ax = sns.barplot(x=players_report['f1-score'], y=players_report.index, orient=\"h\")\n",
        "ax.set(xlabel='F1-Score', ylabel='Metric')\n",
        "pl.title('Classification Report Metrics')\n",
        "pl.show()"
      ],
      "id": "93b7b1a3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# Assuming you have already trained your Naive Bayes model (nb_model) and split your data into training (X_train, y_train) and testing (X_test, y_test) sets.\n",
        "\n",
        "# Example data (replace with your actual data)\n",
        "# X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "# nb_model = MultinomialNB()\n",
        "# nb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities on the test data\n",
        "y_probs = nb_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Binarize the target variable\n",
        "y_test_binary = label_binarize(y_test, classes=np.unique(y_test))\n",
        "\n",
        "# Calculate precision-recall curve\n",
        "precision, recall, _ = precision_recall_curve(y_test_binary, y_probs)\n",
        "\n",
        "# Calculate ROC curve\n",
        "fpr, tpr, _ = roc_curve(y_test_binary, y_probs)\n",
        "\n",
        "# Calculate area under the curves (AUC)\n",
        "pr_auc = auc(recall, precision)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot Precision-Recall curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, color='darkorange', lw=2, label=f'PR Curve (AUC = {pr_auc:.2f})')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkblue', lw=2, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "id": "d70b3b03",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}