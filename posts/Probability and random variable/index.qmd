---
title: "Probability and random variable"
author: "Mehran Islam"
date: "2023-12-07"
categories: [code, analysis]
image: "image.jpg"
---

This is a post about probability of survival in the Titanic disaster.

Importing the libraries required:

```{python}
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, classification_report
from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
```

```{python}
# Load the Titanic dataset
titanic_df = pd.read_csv('titanic.csv')
```

```{python}
# Let's assume 'Survived' is the target variable
# Drop irrelevant columns or handle missing data as needed
features = ['PassengerId','Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch','Fare']
target = 'Survived'
```

```{python}
# Convert categorical variables to numerical
titanic_df['Sex'] = titanic_df['Sex'].map({'male': 0, 'female': 1})
```

```{python}
# Handle missing values
titanic_df = titanic_df.dropna(subset=features + [target])
```

```{python}
# Extract titles from 'Name' and create a new 'Title' column
titanic_df['Title'] = titanic_df['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())
```

```{python}
# Drop 'Name' column
titanic_df = titanic_df.drop(columns=['Name'])
```

```{python}
# One-hot encode categorical features
categorical_features = ['Title', 'Ticket', 'Cabin', 'Embarked']
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(), categorical_features)
    ],
    remainder='passthrough'
)
```

```{python}
# Separate features and target variable
X = titanic_df[features]
y = titanic_df[target]
```

```{python}
# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

```

```{python}
# Train a logistic regression model
model = GaussianNB()
model.fit(X_train, y_train)
```

```{python}
# Make predictions on the test set
y_pred = model.predict(X_test)
y_pred_proba = model.predict_proba(X_test)[:, 1]
```

```{python}
# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
classification_rep = classification_report(y_test, y_pred)
```

```{python}
print(f"Accuracy: {accuracy:.2f}")
print("Classification Report:\n", classification_rep)

```

```{python}
# Plot the ROC curve and display the AUC score
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import precision_recall_curve, average_precision_score


fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
roc_auc = auc(fpr, tpr)

precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)
average_precision = average_precision_score(y_test, y_pred_proba)

# Plot ROC curve
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {roc_auc:.2f}')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")

# Plot precision-recall curve
plt.subplot(1, 2, 2)
plt.step(recall, precision, color='b', alpha=0.2, where='post')
plt.fill_between(recall, precision, step='post', alpha=0.2, color='b')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.ylim([0.0, 1.05])
plt.xlim([0.0, 1.0])
plt.title('Precision-Recall curve: AP={0:0.2f}'.format(average_precision))

plt.tight_layout()
plt.show()

# Plot probability distribution for positive class
plt.figure(figsize=(8, 6))
plt.hist(y_pred_proba[y_test == 1], bins=50, color='blue', alpha=0.7, label='Survived (1)')
plt.hist(y_pred_proba[y_test == 0], bins=50, color='red', alpha=0.7, label='Not Survived (0)')
plt.xlabel('Predicted Probability')
plt.ylabel('Frequency')
plt.title('Probability Distribution for Positive Class')
plt.legend(loc='upper right')
plt.show()

```
