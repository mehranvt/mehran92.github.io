[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "mehran92.github.io",
    "section": "",
    "text": "Classification\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nDec 7, 2023\n\n\nMehran Islam\n\n\n\n\n\n\n  \n\n\n\n\nOutlier\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nDec 7, 2023\n\n\nMehran Islam\n\n\n\n\n\n\n  \n\n\n\n\nPost With Code\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nDec 7, 2023\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nDec 4, 2023\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/Classification/index.html",
    "href": "posts/Classification/index.html",
    "title": "Classification",
    "section": "",
    "text": "Classification Post\nImport the required librariesundefined\n\nimport pandas as pd\n\n\nimport numpy as np\nimport matplotlib.pyplot as pl\nimport seaborn as sns\n\nRead data from file and identify null values\n\ndata=pd.read_csv('athlete_events.csv', index_col=\"ID\")\n\n{data.apply(pd.isnull).sum()/data.shape[0]}\n\nathletes= data[[\"Team\",\"Sex\", \"Season\",\"Sport\",\"Medal\"]].copy()\n\n#converting into column\nathletes.columns = [\"country\",\"sex\",\"season\", \"sport\",\"medal\"]\n\nathletes\n\n\n\n\n\n\n\n\ncountry\nsex\nseason\nsport\nmedal\n\n\nID\n\n\n\n\n\n\n\n\n\n1\nChina\nM\nSummer\nBasketball\nNaN\n\n\n2\nChina\nM\nSummer\nJudo\nNaN\n\n\n3\nDenmark\nM\nSummer\nFootball\nNaN\n\n\n4\nDenmark/Sweden\nM\nSummer\nTug-Of-War\nGold\n\n\n5\nNetherlands\nF\nWinter\nSpeed Skating\nNaN\n\n\n...\n...\n...\n...\n...\n...\n\n\n135569\nPoland-1\nM\nWinter\nLuge\nNaN\n\n\n135570\nPoland\nM\nWinter\nSki Jumping\nNaN\n\n\n135570\nPoland\nM\nWinter\nSki Jumping\nNaN\n\n\n135571\nPoland\nM\nWinter\nBobsleigh\nNaN\n\n\n135571\nPoland\nM\nWinter\nBobsleigh\nNaN\n\n\n\n\n271116 rows × 5 columns\n\n\n\n\nathletes.apply(pd.isnull).sum()/athletes.shape[0]\n\ncountry    0.000000\nsex        0.000000\nseason     0.000000\nsport      0.000000\nmedal      0.853262\ndtype: float64\n\n\n\nathletes = athletes[athletes['medal'].isin(['Gold', 'Silver', 'Bronze'])].dropna(subset=['medal'])\n\n\nathletes\n\n\n\n\n\n\n\n\ncountry\nsex\nseason\nsport\nmedal\n\n\nID\n\n\n\n\n\n\n\n\n\n4\nDenmark/Sweden\nM\nSummer\nTug-Of-War\nGold\n\n\n15\nFinland\nM\nSummer\nSwimming\nBronze\n\n\n15\nFinland\nM\nSummer\nSwimming\nBronze\n\n\n16\nFinland\nM\nWinter\nIce Hockey\nBronze\n\n\n17\nFinland\nM\nSummer\nGymnastics\nBronze\n\n\n...\n...\n...\n...\n...\n...\n\n\n135553\nSoviet Union\nF\nSummer\nAthletics\nSilver\n\n\n135553\nSoviet Union\nF\nSummer\nAthletics\nBronze\n\n\n135554\nPoland\nM\nSummer\nFencing\nBronze\n\n\n135563\nRussia\nF\nSummer\nAthletics\nBronze\n\n\n135563\nRussia\nF\nSummer\nAthletics\nSilver\n\n\n\n\n39783 rows × 5 columns\n\n\n\n\n# here we see a high percentage of null values in medal because only some of the athletes win the medal\n\n# Create a new DataFrame with the converted 'target' column\nnew_athletes = athletes.copy()  # Make a copy to avoid modifying the original DataFrame\n\n# Convert the 'medal' column to 'target' based on the medal values\nnew_athletes['target'] = new_athletes['medal'].apply(lambda x: 'gold' if x =='Gold' else 'no gold')\n\n\nnew_athletes\n\n\n\n\n\n\n\n\ncountry\nsex\nseason\nsport\nmedal\ntarget\n\n\nID\n\n\n\n\n\n\n\n\n\n\n4\nDenmark/Sweden\nM\nSummer\nTug-Of-War\nGold\ngold\n\n\n15\nFinland\nM\nSummer\nSwimming\nBronze\nno gold\n\n\n15\nFinland\nM\nSummer\nSwimming\nBronze\nno gold\n\n\n16\nFinland\nM\nWinter\nIce Hockey\nBronze\nno gold\n\n\n17\nFinland\nM\nSummer\nGymnastics\nBronze\nno gold\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n135553\nSoviet Union\nF\nSummer\nAthletics\nSilver\nno gold\n\n\n135553\nSoviet Union\nF\nSummer\nAthletics\nBronze\nno gold\n\n\n135554\nPoland\nM\nSummer\nFencing\nBronze\nno gold\n\n\n135563\nRussia\nF\nSummer\nAthletics\nBronze\nno gold\n\n\n135563\nRussia\nF\nSummer\nAthletics\nSilver\nno gold\n\n\n\n\n39783 rows × 6 columns\n\n\n\n\n#I just want to include four sports in which US generally do good\n\nselected_sports = ['Swimming']\n\nrecent_athletes = new_athletes[new_athletes['sport'].isin(selected_sports)]\n\n\nrecent_athletes.apply(pd.isnull).sum()\nrecent_athletes\n\n\n\n\n\n\n\n\ncountry\nsex\nseason\nsport\nmedal\ntarget\n\n\nID\n\n\n\n\n\n\n\n\n\n\n15\nFinland\nM\nSummer\nSwimming\nBronze\nno gold\n\n\n15\nFinland\nM\nSummer\nSwimming\nBronze\nno gold\n\n\n100\nHungary\nM\nSummer\nSwimming\nBronze\nno gold\n\n\n259\nCanada\nF\nSummer\nSwimming\nBronze\nno gold\n\n\n424\nSouth Africa\nF\nSummer\nSwimming\nBronze\nno gold\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n135302\nWest Germany\nF\nSummer\nSwimming\nBronze\nno gold\n\n\n135396\nNetherlands\nM\nSummer\nSwimming\nBronze\nno gold\n\n\n135415\nSoviet Union\nM\nSummer\nSwimming\nGold\ngold\n\n\n135489\nRussia\nF\nSummer\nSwimming\nSilver\nno gold\n\n\n135522\nNetherlands\nM\nSummer\nSwimming\nSilver\nno gold\n\n\n\n\n3048 rows × 6 columns\n\n\n\n\n#lets drop silver medals and gold medals because we are only interested in Gold medals\n\n#athletes = athletes[athletes['medal'] == 'Gold'].dropna(subset=['medal'])\n\n\n# Create a new DataFrame with the converted columns\nplayers = recent_athletes.copy()  # Make a copy to avoid modifying the original DataFrame\n\n# Convert the 'country' column to numerical values\nplayers['country'] = (recent_athletes['country'] == 'United States').astype(int)\n\n# Convert the 'sex' column to numerical values\nplayers['sex'] = (recent_athletes['sex'] == 'M').astype(int)\n\n\n# Convert the 'season' column to numerical values\nplayers['season'] = (recent_athletes['season'] == 'Summer').astype(int)\n\n# Convert the 'sport' column to numerical values\nplayers['sport'] = (recent_athletes['sport'] == 'Swimming').astype(int)\n\n\n#since we are only interested in swimming data let's drop others\n\n#athletes = athletes[athletes['sport'] == 'Swimming'].dropna(subset=['sport'])\n\n\nplayers\n\n\n\n\n\n\n\n\ncountry\nsex\nseason\nsport\nmedal\ntarget\n\n\nID\n\n\n\n\n\n\n\n\n\n\n15\n0\n1\n1\n1\nBronze\nno gold\n\n\n15\n0\n1\n1\n1\nBronze\nno gold\n\n\n100\n0\n1\n1\n1\nBronze\nno gold\n\n\n259\n0\n0\n1\n1\nBronze\nno gold\n\n\n424\n0\n0\n1\n1\nBronze\nno gold\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n135302\n0\n0\n1\n1\nBronze\nno gold\n\n\n135396\n0\n1\n1\n1\nBronze\nno gold\n\n\n135415\n0\n1\n1\n1\nGold\ngold\n\n\n135489\n0\n0\n1\n1\nSilver\nno gold\n\n\n135522\n0\n1\n1\n1\nSilver\nno gold\n\n\n\n\n3048 rows × 6 columns\n\n\n\n\n# Split the data into features (X) and the target variable (y)\n# to preapre data for ML ready\n\nfrom sklearn.model_selection import train_test_split\nX = players[['country','sport', 'sex']]\ny = players['target']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n\nplayers\n\n\n\n\n\n\n\n\ncountry\nsex\nseason\nsport\nmedal\ntarget\n\n\nID\n\n\n\n\n\n\n\n\n\n\n15\n0\n1\n1\n1\nBronze\nno gold\n\n\n15\n0\n1\n1\n1\nBronze\nno gold\n\n\n100\n0\n1\n1\n1\nBronze\nno gold\n\n\n259\n0\n0\n1\n1\nBronze\nno gold\n\n\n424\n0\n0\n1\n1\nBronze\nno gold\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n135302\n0\n0\n1\n1\nBronze\nno gold\n\n\n135396\n0\n1\n1\n1\nBronze\nno gold\n\n\n135415\n0\n1\n1\n1\nGold\ngold\n\n\n135489\n0\n0\n1\n1\nSilver\nno gold\n\n\n135522\n0\n1\n1\n1\nSilver\nno gold\n\n\n\n\n3048 rows × 6 columns\n\n\n\n\nX_test.shape\n\n(1524, 3)\n\n\n\nsns.countplot(data=players, x='target')\npl.title('Distribution of Target')\npl.show()\n\n\n\n\n\n# to train the naive model as out target is to use naive bayes model\n\n# we use gaussian naive bayes\n\nfrom sklearn.naive_bayes import GaussianNB\n\n# Create a Gaussian Naive Bayes model\nnb_model = GaussianNB()\n\n# Train the model on the training data\nnb_model.fit(X_train, y_train)\n\nGaussianNB()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.GaussianNBGaussianNB()\n\n\n\n# now evaluating the model \n\n\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Predict on the test data\ny_pred = nb_model.predict(X_test)\n\n# Calculate accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy:\", accuracy)\n\n# Generate a classification report\nreport = classification_report(y_test, y_pred)\nprint(\"Classification Report:\\n\", report)\n\nAccuracy: 0.7099737532808399\nClassification Report:\n               precision    recall  f1-score   support\n\n        gold       0.59      0.58      0.58       537\n     no gold       0.77      0.78      0.78       987\n\n    accuracy                           0.71      1524\n   macro avg       0.68      0.68      0.68      1524\nweighted avg       0.71      0.71      0.71      1524\n\n\n\n\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.model_selection import train_test_split\n\n# Assuming you have already trained your Naive Bayes model (nb_model) and split your data into training (X_train, y_train) and testing (X_test, y_test) sets.\n\n# Example data (replace with your actual data)\n# X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n# nb_model = MultinomialNB()\n# nb_model.fit(X_train, y_train)\n\n# Predict on the test data\ny_pred = nb_model.predict(X_test)\n\n# Create a confusion matrix\ncm = confusion_matrix(y_test, y_pred)\n\n# Create a heatmap using seaborn\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\n\n\n\n\n\n# Assuming you have the classification report stored in the 'report' variable\nreport = classification_report(y_test, y_pred, output_dict=True)\n\n# Convert the classification report to a DataFrame for easier plotting\nplayers_report = pd.DataFrame(report).transpose()\n\n# Create a horizontal bar chart using Seaborn\npl.figure(figsize=(8, 4))\nsns.set(style=\"whitegrid\")\nsns.set_palette(\"pastel\")\nax = sns.barplot(x=players_report['f1-score'], y=players_report.index, orient=\"h\")\nax.set(xlabel='F1-Score', ylabel='Metric')\npl.title('Classification Report Metrics')\npl.show()\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import precision_recall_curve, roc_curve, auc\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import label_binarize\n\n# Assuming you have already trained your Naive Bayes model (nb_model) and split your data into training (X_train, y_train) and testing (X_test, y_test) sets.\n\n# Example data (replace with your actual data)\n# X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n# nb_model = MultinomialNB()\n# nb_model.fit(X_train, y_train)\n\n# Predict probabilities on the test data\ny_probs = nb_model.predict_proba(X_test)[:, 1]\n\n# Binarize the target variable\ny_test_binary = label_binarize(y_test, classes=np.unique(y_test))\n\n# Calculate precision-recall curve\nprecision, recall, _ = precision_recall_curve(y_test_binary, y_probs)\n\n# Calculate ROC curve\nfpr, tpr, _ = roc_curve(y_test_binary, y_probs)\n\n# Calculate area under the curves (AUC)\npr_auc = auc(recall, precision)\nroc_auc = auc(fpr, tpr)\n\n# Plot Precision-Recall curve\nplt.figure(figsize=(8, 6))\nplt.plot(recall, precision, color='darkorange', lw=2, label=f'PR Curve (AUC = {pr_auc:.2f})')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-Recall Curve')\nplt.legend(loc='best')\nplt.show()\n\n# Plot ROC curve\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, color='darkblue', lw=2, label=f'ROC Curve (AUC = {roc_auc:.2f})')\nplt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve')\nplt.legend(loc='best')\nplt.show()"
  },
  {
    "objectID": "posts/Outlier/index.html",
    "href": "posts/Outlier/index.html",
    "title": "Outlier",
    "section": "",
    "text": "Importing libraries\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as pl\nimport seaborn as sns\n\nRead the data\n\nimport pandas as pd\n\n# Read the data\ndata = pd.read_csv('Cricket_data.txt', sep='\\t')\n\n# Display the first few rows of the data\ndata\n\n\n\n\n\n\n\n\nPlayer\nSpan\nMat\nInn\nNO\nRuns\nHS\nAvg\n100\n50\n0\nPlayer Profile\n\n\n\n\n0\nSR Tendulkar (INDIA)\n1989-2013\n200\n329\n33\n15921\n248*\n53.78\n51\n68\n14\nhttp://stats.espncricinfo.com/ci/content/playe...\n\n\n1\nRT Ponting (AUS)\n1995-2012\n168\n287\n29\n13378\n257\n51.85\n41\n62\n17\nhttp://stats.espncricinfo.com/ci/content/playe...\n\n\n2\nJH Kallis (ICC/SA)\n1995-2013\n166\n280\n40\n13289\n224\n55.37\n45\n58\n16\nhttp://stats.espncricinfo.com/ci/content/playe...\n\n\n3\nR Dravid (ICC/INDIA)\n1996-2012\n164\n286\n32\n13288\n270\n52.31\n36\n63\n8\nhttp://stats.espncricinfo.com/ci/content/playe...\n\n\n4\nAN Cook (ENG)\n2006-2018\n161\n291\n16\n12472\n294\n45.35\n33\n57\n9\nhttp://stats.espncricinfo.com/ci/content/playe...\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2996\nCA Snedden (NZ)\n1947-1947\n1\n-\n-\n-\n-\n-\n-\n-\n-\nhttp://stats.espncricinfo.com/ci/content/playe...\n\n\n2997\nVN Swamy (INDIA)\n1955-1955\n1\n-\n-\n-\n-\n-\n-\n-\n-\nhttp://stats.espncricinfo.com/ci/content/playe...\n\n\n2998\nUsman Shinwari (PAK)\n2019-2019\n1\n-\n-\n-\n-\n-\n-\n-\n-\nhttp://stats.espncricinfo.com/ci/content/playe...\n\n\n2999\nCM Willoughby (SA)\n2003-2003\n2\n-\n-\n-\n-\n-\n-\n-\n-\nhttp://stats.espncricinfo.com/ci/content/playe...\n\n\n3000\nJW Wilson (AUS)\n1956-1956\n1\n-\n-\n-\n-\n-\n-\n-\n-\nhttp://stats.espncricinfo.com/ci/content/playe...\n\n\n\n\n3001 rows × 12 columns\n\n\n\nIdentify null data\n\ndata.apply(pd.isnull).sum()/data.shape[0]\n\nPlayer            0.0\nSpan              0.0\nMat               0.0\nInn               0.0\nNO                0.0\nRuns              0.0\nHS                0.0\nAvg               0.0\n100               0.0\n50                0.0\n0                 0.0\nPlayer Profile    0.0\ndtype: float64\n\n\n\ndata.describe(include='object')\n\n\n\n\n\n\n\n\nPlayer\nSpan\nInn\nNO\nRuns\nHS\nAvg\n100\n50\n0\nPlayer Profile\n\n\n\n\ncount\n3001\n3001\n3001\n3001\n3001\n3001\n3001\n3001\n3001\n3001\n3001\n\n\nunique\n2995\n1140\n198\n49\n1188\n465\n1598\n40\n57\n35\n3001\n\n\ntop\nImran Khan (PAK)\n2019-2019\n2\n0\n0\n5\n-\n0\n0\n0\nhttp://stats.espncricinfo.com/ci/content/playe...\n\n\nfreq\n2\n45\n374\n953\n52\n40\n88\n2203\n1619\n854\n1\n\n\n\n\n\n\n\n\ncricket=data[[\"Player\",\"Span\",\"Mat\",\"Inn\",\"Runs\",\"Avg\",\"100\",\"50\"]].copy()\ncricket.columns=[\"player\",\"span\",\"mat\",\"inn\",\"runs\",\"avg\",\"100\",\"50\"]\ncricket.head()\n\n\n\n\n\n\n\n\nplayer\nspan\nmat\ninn\nruns\navg\n100\n50\n\n\n\n\n0\nSR Tendulkar (INDIA)\n1989-2013\n200\n329\n15921\n53.78\n51\n68\n\n\n1\nRT Ponting (AUS)\n1995-2012\n168\n287\n13378\n51.85\n41\n62\n\n\n2\nJH Kallis (ICC/SA)\n1995-2013\n166\n280\n13289\n55.37\n45\n58\n\n\n3\nR Dravid (ICC/INDIA)\n1996-2012\n164\n286\n13288\n52.31\n36\n63\n\n\n4\nAN Cook (ENG)\n2006-2018\n161\n291\n12472\n45.35\n33\n57\n\n\n\n\n\n\n\nconverting to numerical int data\n\n# Convert the 'runs' column to a numeric data type (int)\ncricket['runs'] = cricket['runs'].str.replace(',', '', regex=True).str.extract('(\\d+)').astype(float)\n\n# Filter the data to select players with more than 5000 runs\nbatsman = cricket[cricket['runs'] &gt; 2000]\n\n# Display the filtered data in column form\nbatsman.head()\n\n\n\n\n\n\n\n\nplayer\nspan\nmat\ninn\nruns\navg\n100\n50\n\n\n\n\n0\nSR Tendulkar (INDIA)\n1989-2013\n200\n329\n15921.0\n53.78\n51\n68\n\n\n1\nRT Ponting (AUS)\n1995-2012\n168\n287\n13378.0\n51.85\n41\n62\n\n\n2\nJH Kallis (ICC/SA)\n1995-2013\n166\n280\n13289.0\n55.37\n45\n58\n\n\n3\nR Dravid (ICC/INDIA)\n1996-2012\n164\n286\n13288.0\n52.31\n36\n63\n\n\n4\nAN Cook (ENG)\n2006-2018\n161\n291\n12472.0\n45.35\n33\n57\n\n\n\n\n\n\n\n\n# Use .loc to update the 'Player' column\nbatsman.loc[:, 'player'] = batsman['player'].str.replace(r'\\s*\\(.*\\)', '', regex=True)\n\n# Display the DataFrame with the country names removed\n\nbatsman.tail()\n\n\n\n\n\n\n\n\nplayer\nspan\nmat\ninn\nruns\navg\n100\n50\n\n\n\n\n308\nCJL Rogers\n2008-2015\n25\n48\n2015.0\n42.87\n5\n14\n\n\n309\nKOA Powell\n2011-2018\n40\n76\n2011.0\n26.81\n3\n6\n\n\n310\nAC Hudson\n1992-1998\n35\n63\n2007.0\n33.45\n4\n13\n\n\n311\nKL Rahul\n2014-2019\n36\n60\n2006.0\n34.58\n5\n11\n\n\n312\nDN Sardesai\n1961-1972\n30\n55\n2001.0\n39.23\n5\n9\n\n\n\n\n\n\n\n\n# List of names to delete\nnames_to_delete = ['SR Tendulkar', 'DG Bradman']\n\n# Filter out rows with the specified names\nbatsman = batsman[~batsman['player'].isin(names_to_delete)]\n\nbatsman.head()\n\n\n\n\n\n\n\n\nplayer\nspan\nmat\ninn\nruns\navg\n100\n50\n\n\n\n\n1\nRT Ponting\n1995-2012\n168\n287\n13378.0\n51.85\n41\n62\n\n\n2\nJH Kallis\n1995-2013\n166\n280\n13289.0\n55.37\n45\n58\n\n\n3\nR Dravid\n1996-2012\n164\n286\n13288.0\n52.31\n36\n63\n\n\n4\nAN Cook\n2006-2018\n161\n291\n12472.0\n45.35\n33\n57\n\n\n5\nKC Sangakkara\n2000-2015\n134\n233\n12400.0\n57.4\n38\n52\n\n\n\n\n\n\n\n\n#to save the players name for future \nplayer = batsman['player'].tolist()\n\n\n# Split the 'span' values into start and end years\nbatsman[['Start_Year', 'End_Year']] = batsman['span'].str.split('-', expand=True).astype(int)\n\n# Calculate the duration in years\nbatsman['Span_yrs'] = batsman['End_Year'] - batsman['Start_Year'] + 1  # Adding 1 to include both start and end years\n\n# Display the DataFrame with the duration calculated\nbatsman\n\n\n\n\n\n\n\n\nplayer\nspan\nmat\ninn\nruns\navg\n100\n50\nStart_Year\nEnd_Year\nSpan_yrs\n\n\n\n\n1\nRT Ponting\n1995-2012\n168\n287\n13378.0\n51.85\n41\n62\n1995\n2012\n18\n\n\n2\nJH Kallis\n1995-2013\n166\n280\n13289.0\n55.37\n45\n58\n1995\n2013\n19\n\n\n3\nR Dravid\n1996-2012\n164\n286\n13288.0\n52.31\n36\n63\n1996\n2012\n17\n\n\n4\nAN Cook\n2006-2018\n161\n291\n12472.0\n45.35\n33\n57\n2006\n2018\n13\n\n\n5\nKC Sangakkara\n2000-2015\n134\n233\n12400.0\n57.4\n38\n52\n2000\n2015\n16\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n308\nCJL Rogers\n2008-2015\n25\n48\n2015.0\n42.87\n5\n14\n2008\n2015\n8\n\n\n309\nKOA Powell\n2011-2018\n40\n76\n2011.0\n26.81\n3\n6\n2011\n2018\n8\n\n\n310\nAC Hudson\n1992-1998\n35\n63\n2007.0\n33.45\n4\n13\n1992\n1998\n7\n\n\n311\nKL Rahul\n2014-2019\n36\n60\n2006.0\n34.58\n5\n11\n2014\n2019\n6\n\n\n312\nDN Sardesai\n1961-1972\n30\n55\n2001.0\n39.23\n5\n9\n1961\n1972\n12\n\n\n\n\n311 rows × 11 columns\n\n\n\n\n#sns.pairplot(batsman)\n#pl.show()\n\n\nbatsman = batsman.drop(['player'], axis = 1)\nbatsman.head()\n\n\n\n\n\n\n\n\nspan\nmat\ninn\nruns\navg\n100\n50\nStart_Year\nEnd_Year\nSpan_yrs\n\n\n\n\n1\n1995-2012\n168\n287\n13378.0\n51.85\n41\n62\n1995\n2012\n18\n\n\n2\n1995-2013\n166\n280\n13289.0\n55.37\n45\n58\n1995\n2013\n19\n\n\n3\n1996-2012\n164\n286\n13288.0\n52.31\n36\n63\n1996\n2012\n17\n\n\n4\n2006-2018\n161\n291\n12472.0\n45.35\n33\n57\n2006\n2018\n13\n\n\n5\n2000-2015\n134\n233\n12400.0\n57.4\n38\n52\n2000\n2015\n16\n\n\n\n\n\n\n\n\ncolumns=[\"runs\",\"avg\",\"100\"]\n\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.decomposition import PCA\n\n# Initialize PCA with the number of components you want to retain\nn_components = 2  # Adjust as needed\npca = PCA(n_components=n_components)\n\n# Initialize the MinMaxScaler\nscaler = MinMaxScaler()\n\n# Apply Min-Max scaling to your data\nscaled_data = scaler.fit_transform(batsman[columns])\n\n# Fit and transform PCA on the scaled data\nbatter = pca.fit_transform(scaled_data)\n\nbatter\n\narray([[ 1.03695410e+00, -2.69940761e-01],\n       [ 1.12062664e+00, -2.12675013e-01],\n       [ 9.72643357e-01, -2.41727294e-01],\n       [ 8.12777697e-01, -3.26136693e-01],\n       [ 1.00133191e+00, -1.13313620e-01],\n       [ 8.76027429e-01, -1.65416432e-01],\n       [ 8.03714570e-01, -1.77324674e-01],\n       [ 8.35535348e-01, -2.16051623e-01],\n       [ 7.16629780e-01, -1.52257191e-01],\n       [ 7.71731820e-01, -1.47529266e-01],\n       [ 7.51496323e-01, -1.16826152e-01],\n       [ 7.60099920e-01, -9.84197453e-02],\n       [ 5.78313905e-01, -1.44447188e-01],\n       [ 5.81720742e-01, -1.10475759e-01],\n       [ 4.10454723e-01, -1.78356682e-01],\n       [ 5.51630093e-01,  2.02856905e-03],\n       [ 5.45407348e-01, -5.96393461e-02],\n       [ 4.01370162e-01, -1.00331450e-01],\n       [ 5.14558283e-01, -2.75678222e-02],\n       [ 5.67684501e-01, -7.00287954e-02],\n       [ 6.09662762e-01, -4.50051328e-02],\n       [ 5.02929967e-01, -4.73960233e-02],\n       [ 5.22583395e-01, -3.18357048e-02],\n       [ 2.88727946e-01, -2.00119529e-01],\n       [ 3.64045829e-01, -1.11125154e-01],\n       [ 4.57542834e-01, -6.78757801e-02],\n       [ 4.45567474e-01, -5.35478544e-02],\n       [ 5.99487129e-01,  1.25646805e-01],\n       [ 3.51933656e-01, -1.53985937e-01],\n       [ 2.39332032e-01, -2.05109852e-01],\n       [ 3.69502154e-01, -1.30341543e-01],\n       [ 4.08069878e-01, -8.38606584e-02],\n       [ 3.78184869e-01, -1.00150691e-01],\n       [ 3.43006322e-01, -7.55111423e-02],\n       [ 4.86257974e-01,  5.16171859e-02],\n       [ 3.27965069e-01, -9.70326853e-02],\n       [ 3.61347897e-01, -3.71496336e-02],\n       [ 3.00150266e-01, -1.14648941e-01],\n       [ 3.49336173e-01, -9.57022464e-02],\n       [ 3.45310967e-01,  8.55973620e-03],\n       [ 3.58956301e-01, -5.95034750e-02],\n       [ 5.10205303e-01,  1.85504652e-01],\n       [ 2.44794917e-01, -9.51892914e-02],\n       [ 2.57377824e-01, -9.84092269e-02],\n       [ 5.34353047e-01,  1.06940810e-01],\n       [ 1.42898156e-01, -1.14213277e-01],\n       [ 6.03399858e-01,  2.58853727e-01],\n       [ 3.38367599e-01, -2.13239846e-02],\n       [ 4.78770635e-01,  9.96540401e-02],\n       [ 4.04356726e-01, -1.85011346e-03],\n       [ 2.97842037e-01, -1.29782098e-01],\n       [ 1.95539194e-01, -1.20780230e-01],\n       [ 4.36726719e-01,  1.73972519e-01],\n       [ 2.49890744e-01, -8.69695367e-02],\n       [ 4.61362275e-01,  2.15576042e-01],\n       [ 2.56943603e-01, -3.10402788e-02],\n       [ 1.24628706e-01, -1.18122510e-01],\n       [ 3.72297707e-01,  9.63198443e-02],\n       [ 2.67999048e-01, -5.80715056e-02],\n       [ 3.39226040e-01,  1.10467776e-01],\n       [ 2.44932715e-01,  4.87340514e-02],\n       [ 3.07177760e-01, -1.93141179e-02],\n       [ 1.69071959e-01, -4.97705669e-02],\n       [ 3.26657407e-01,  4.99214279e-02],\n       [ 1.63834349e-01, -4.62725445e-02],\n       [ 2.08151008e-01, -7.06237100e-04],\n       [ 1.85766330e-01, -3.05675800e-02],\n       [ 1.42391333e-01, -7.46897299e-02],\n       [ 1.68972338e-01, -1.58399635e-04],\n       [ 2.73307932e-01,  1.08470393e-01],\n       [ 1.77417998e-01, -2.61282404e-03],\n       [ 9.48593095e-02, -1.20992480e-01],\n       [ 7.42494950e-02, -1.31239104e-01],\n       [ 2.76050035e-01,  9.74892335e-02],\n       [ 1.88975445e-01, -5.18534205e-02],\n       [ 9.88132770e-02,  2.23320355e-02],\n       [ 2.33350625e-01,  7.30374883e-02],\n       [-1.08240404e-01, -2.10408152e-01],\n       [ 1.24989870e-01, -8.11846944e-02],\n       [ 1.45343902e-01, -4.41049051e-02],\n       [ 2.01086357e-01,  1.08891803e-01],\n       [ 2.02152732e-01,  3.67767048e-02],\n       [ 2.98245689e-01,  2.60977984e-01],\n       [ 2.02488406e-01,  1.01097090e-01],\n       [ 1.26622896e-01, -4.40343071e-03],\n       [ 5.12523207e-02, -8.36493380e-02],\n       [ 1.29095762e-01,  4.72859215e-03],\n       [-7.72338666e-02, -1.93873285e-01],\n       [ 1.57921020e-01,  9.20679126e-02],\n       [ 1.13152416e-01,  9.20617195e-02],\n       [ 2.34169850e-02, -1.63928198e-01],\n       [ 1.01019658e-01,  3.19870990e-02],\n       [-8.71603846e-02, -8.82939275e-02],\n       [ 1.09980032e-01,  5.87334000e-02],\n       [ 8.24017777e-02,  6.22027567e-02],\n       [-4.91437303e-02, -3.94877019e-02],\n       [ 9.47966632e-02,  1.11322953e-01],\n       [ 1.66589278e-01,  1.96826058e-01],\n       [ 2.56810355e-02,  6.06391137e-02],\n       [-6.59269521e-03, -6.73537491e-02],\n       [ 1.92347234e-02, -9.20554752e-02],\n       [ 3.02151567e-01,  3.66746500e-01],\n       [ 1.00060731e-01,  6.42564644e-02],\n       [ 4.68151045e-02,  4.89768884e-02],\n       [ 1.13612942e-01,  1.15984532e-01],\n       [-1.55462440e-01, -1.75345626e-01],\n       [ 1.76299278e-02, -2.51627784e-02],\n       [ 7.23318643e-02,  1.50964440e-01],\n       [ 2.60931432e-01,  3.34693588e-01],\n       [-5.03523821e-02, -5.19684831e-02],\n       [-4.46116426e-02, -4.10474759e-02],\n       [-5.20165046e-02, -7.86681131e-02],\n       [ 1.01776298e-01,  1.14338074e-01],\n       [ 6.78489514e-02,  8.15107082e-02],\n       [-1.47099579e-01, -1.14503232e-01],\n       [ 3.32199349e-02,  4.94933098e-02],\n       [-2.19051701e-01, -2.10097395e-01],\n       [-7.84332820e-03,  6.06306675e-02],\n       [-3.29268487e-02, -7.78594359e-03],\n       [-9.49732882e-02, -8.51695311e-02],\n       [-7.17511886e-03,  2.16503896e-02],\n       [ 1.19042440e-02,  8.39256407e-02],\n       [-1.19748304e-01, -6.61085582e-02],\n       [ 3.64614668e-02,  1.08359831e-01],\n       [-1.11995067e-02,  5.54261054e-02],\n       [-4.19264601e-02, -1.80637938e-02],\n       [ 3.11015116e-02,  8.45084553e-02],\n       [-5.88884348e-02,  3.10344656e-02],\n       [ 4.66458937e-02,  1.20449028e-01],\n       [-1.33773810e-01, -6.44528491e-02],\n       [-2.19096508e-02, -1.48820035e-02],\n       [-6.92407695e-02,  1.18381927e-02],\n       [-1.49920684e-01, -1.01797448e-01],\n       [ 3.50935127e-02,  9.46395959e-02],\n       [-1.06514841e-01,  3.32468372e-02],\n       [ 5.22381923e-02,  2.09255002e-01],\n       [-9.78291636e-03,  5.16745495e-02],\n       [-1.88979911e-01, -1.08610441e-01],\n       [-6.87392895e-03,  1.09435129e-01],\n       [-7.00840055e-02, -5.15364516e-02],\n       [-1.15147424e-01,  6.10574957e-04],\n       [-3.87481938e-02,  5.88888277e-02],\n       [ 2.02380272e-01,  3.27858691e-01],\n       [-1.11730282e-01, -4.15650698e-02],\n       [-2.25324485e-01, -8.63028446e-02],\n       [-1.71844965e-01, -3.64910562e-02],\n       [-1.34187486e-01, -1.91752891e-02],\n       [-3.69540233e-02,  4.78861428e-03],\n       [-1.71381849e-02,  6.51502178e-02],\n       [-7.34114562e-02, -5.91399378e-03],\n       [-5.75917923e-02,  2.30840761e-02],\n       [-2.83006076e-01, -1.91247239e-01],\n       [ 3.33339638e-02,  1.58437139e-01],\n       [-1.02383908e-04,  7.43822169e-02],\n       [-7.87809311e-02,  4.09968178e-02],\n       [ 2.95669284e-02,  1.54609915e-01],\n       [-7.22870987e-02,  5.48372246e-02],\n       [-5.21308086e-02,  1.70071317e-02],\n       [-1.10533170e-02,  9.19588622e-02],\n       [ 3.97323609e-02,  1.58368114e-01],\n       [-1.24743515e-02,  1.95829181e-01],\n       [-1.06918998e-01,  7.76221043e-03],\n       [-1.54485568e-01, -7.40340240e-02],\n       [ 1.05616595e-02,  2.18474363e-01],\n       [-2.22395631e-01, -1.36146301e-01],\n       [-1.81489531e-01, -8.87753841e-02],\n       [-1.84129573e-01, -6.49506023e-02],\n       [-1.08919850e-01,  4.34782382e-02],\n       [-2.07659712e-01, -9.95826726e-02],\n       [-1.64317391e-01, -9.90157199e-02],\n       [-2.17366307e-01, -8.21573550e-02],\n       [-2.00501651e-01, -5.23493411e-02],\n       [-6.69415558e-02,  3.40052099e-03],\n       [-1.75512781e-01, -3.22704912e-03],\n       [-1.09635740e-01,  6.26057227e-02],\n       [-2.22298842e-01, -5.71042539e-02],\n       [-1.63148473e-01,  2.27804526e-02],\n       [-4.32843292e-02,  1.57131884e-01],\n       [-1.21661458e-01,  5.08748426e-02],\n       [-6.42527385e-02,  1.01158312e-01],\n       [-9.27412577e-02,  5.58099383e-02],\n       [-1.12309242e-01,  4.82601944e-02],\n       [-4.20840435e-01, -3.12271903e-01],\n       [-4.47225795e-01, -3.32335854e-01],\n       [-3.18263120e-01, -1.53323402e-01],\n       [-1.46827777e-01,  4.57550492e-02],\n       [-1.50968466e-01,  6.53520474e-02],\n       [-8.50566189e-02,  1.30081139e-01],\n       [-3.63418800e-01, -2.01726736e-01],\n       [-1.15874799e-02,  1.86579304e-01],\n       [-1.93458784e-01, -2.31894059e-03],\n       [-2.71496818e-01, -8.27396961e-02],\n       [-1.22931353e-01,  1.02718820e-01],\n       [-1.46026682e-01,  9.08879159e-02],\n       [-7.52426834e-02,  1.63707623e-01],\n       [-1.47984015e-01,  4.04703515e-02],\n       [ 4.65070861e-02,  3.30241476e-01],\n       [-1.59058886e-01,  2.18147607e-02],\n       [-1.19747836e-01,  9.38204034e-02],\n       [-8.31786090e-02,  1.59862655e-01],\n       [-3.19479989e-01, -1.73621212e-01],\n       [-3.66779452e-01, -2.30871752e-01],\n       [-1.10946990e-01,  9.08230352e-02],\n       [-2.50881443e-01, -5.12294442e-02],\n       [-3.42617513e-01, -1.58245126e-01],\n       [-1.59088411e-01,  6.11266203e-02],\n       [-3.33089958e-01, -1.40550783e-01],\n       [-2.43954898e-01, -3.50303738e-02],\n       [-2.85195092e-01, -5.30848455e-02],\n       [-2.10513258e-01,  2.47873542e-03],\n       [-2.14036128e-01,  2.21380297e-02],\n       [-1.62973038e-01,  3.69459014e-02],\n       [-2.03391840e-01, -6.22392014e-03],\n       [-1.38643396e-01,  1.07828000e-01],\n       [-2.80267536e-01, -1.13638065e-01],\n       [-9.05721250e-02,  1.93273490e-01],\n       [-2.01752757e-01, -1.02596874e-03],\n       [-1.24685642e-01,  1.85071930e-01],\n       [-4.75762876e-02,  1.94107466e-01],\n       [-3.40622437e-01, -1.39322393e-01],\n       [-1.13492608e-01,  1.05437920e-01],\n       [-6.39552493e-02,  2.44371702e-01],\n       [-2.99925697e-01, -1.16541674e-01],\n       [-2.60848014e-01, -4.78559667e-02],\n       [-3.23137294e-01, -2.07652675e-01],\n       [-1.64582588e-01,  9.68426954e-02],\n       [-1.72049671e-01,  3.53261080e-02],\n       [-9.49622383e-02,  1.70828403e-01],\n       [-2.62111852e-01, -6.75953019e-02],\n       [-1.80152267e-01,  7.59976082e-02],\n       [-2.20618804e-01,  5.84237606e-02],\n       [-1.35015023e-01,  8.21808402e-02],\n       [-2.33855646e-01,  3.68576899e-02],\n       [-2.55764093e-01, -7.67785815e-02],\n       [-2.07713387e-01,  1.11056840e-02],\n       [-3.06024517e-01, -5.72233606e-02],\n       [-2.47171048e-01, -3.03819296e-02],\n       [-3.12817885e-01, -9.10078303e-02],\n       [-2.18943570e-01,  2.32440422e-02],\n       [-3.24764505e-01, -1.10606877e-01],\n       [-3.01764891e-01, -9.57408539e-02],\n       [-1.31960468e-01,  1.51405441e-01],\n       [-2.52423963e-01, -5.88956445e-03],\n       [-2.48869988e-01,  2.87761125e-02],\n       [-2.44899626e-01, -4.07311378e-02],\n       [-8.34628090e-02,  2.42983466e-01],\n       [-1.03730613e-01,  2.08529365e-01],\n       [-2.88219544e-01,  1.33028008e-02],\n       [-4.67035204e-01, -2.98208266e-01],\n       [-1.79042376e-01,  1.06909515e-01],\n       [-2.63867207e-01,  3.70872467e-02],\n       [-2.25685235e-01, -2.37556116e-02],\n       [-1.62724863e-01,  1.12118435e-01],\n       [-3.44367801e-01, -1.28612606e-01],\n       [-1.67454351e-01,  8.07816129e-02],\n       [-2.61562817e-01, -3.14053081e-02],\n       [-1.69418827e-01,  1.04624187e-01],\n       [-1.34614191e-01,  1.40006025e-01],\n       [-4.29051279e-01, -2.47508470e-01],\n       [-1.38174491e-01,  1.09114219e-01],\n       [-2.99144867e-01, -6.62619705e-02],\n       [-2.95579028e-01, -3.37591492e-02],\n       [-3.18561486e-01, -9.73338407e-02],\n       [-3.61250904e-01, -1.15886729e-01],\n       [-3.32044882e-01, -6.11303887e-02],\n       [-1.57317658e-01,  1.18466784e-01],\n       [-3.09977928e-01, -4.52763818e-02],\n       [-1.00622226e-01,  2.19879905e-01],\n       [-3.51676939e-01, -6.48617573e-02],\n       [-2.23341311e-01,  8.31520413e-02],\n       [-3.69362695e-01, -1.71252965e-01],\n       [-3.06575565e-01, -3.52454069e-02],\n       [-2.40290065e-01,  6.05946290e-03],\n       [ 5.67066105e-02,  5.01645325e-01],\n       [-3.54483619e-01, -6.16218864e-02],\n       [-4.65709069e-01, -2.80369135e-01],\n       [-3.01121432e-01, -6.87607568e-02],\n       [-3.21471776e-01, -7.65152049e-02],\n       [-3.87699776e-01, -1.66021407e-01],\n       [-3.13322523e-01, -3.56992481e-02],\n       [-8.92380324e-02,  2.55526813e-01],\n       [ 8.98157600e-02,  4.92599725e-01],\n       [-3.76611450e-01, -1.40645833e-01],\n       [-1.86373370e-01,  1.66924362e-01],\n       [-1.16842412e-01,  2.40171317e-01],\n       [-1.55448349e-01,  1.48524219e-01],\n       [-3.25410462e-01, -7.13260785e-02],\n       [-8.71931257e-02,  2.69296075e-01],\n       [-3.04506372e-01, -5.96909591e-02],\n       [-3.47694704e-01, -3.21252583e-02],\n       [-2.92433178e-01, -3.69588888e-02],\n       [-2.65236978e-01, -1.40200422e-02],\n       [-3.51833789e-01, -8.83994140e-02],\n       [-2.56940587e-01,  2.74901625e-02],\n       [-3.56834903e-01, -1.83670120e-02],\n       [-3.43163744e-01, -7.03134315e-02],\n       [-4.45192325e-01, -1.95780000e-01],\n       [-3.50543041e-01, -5.52201131e-02],\n       [-1.31063595e-01,  2.52461026e-01],\n       [-2.31129012e-01,  7.73244945e-02],\n       [-3.29540858e-01, -4.31221618e-02],\n       [-1.41396698e-01,  1.85345975e-01],\n       [-3.30952653e-01,  6.93052200e-03],\n       [-2.48497842e-01,  7.50795021e-02],\n       [-3.31869221e-01, -1.84607241e-02],\n       [-3.32202777e-01, -4.26859944e-02],\n       [-1.76116955e-01,  1.80304151e-01],\n       [-3.73468537e-01, -1.13454422e-01],\n       [-2.89983513e-01,  7.71112224e-03],\n       [-2.65168411e-01,  2.57546493e-02],\n       [-2.15798217e-01,  1.12891243e-01]])\n\n\n\nexplained_variance = pca.explained_variance_ratio_\nprint(\"Explained variance ratio:\", explained_variance)\n\nExplained variance ratio: [0.83360005 0.1513503 ]\n\n\n\npl.scatter(batter[:, 0], batter[:, 1])\npl.xlabel('Principal Component 1')\npl.ylabel('Principal Component 2')\npl.title('PCA Results')\npl.show()\n\n\n\n\n\ncomponent_loadings = pca.components_\nprint(\"Principal component loadings:\", component_loadings)\n\nPrincipal component loadings: [[ 0.65699203  0.48612356  0.57623377]\n [-0.5063218   0.85082336 -0.14049142]]\n\n\n\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.metrics import silhouette_score\n\n\n# Your data\nX = batter  # Your data points\n\nbest_eps = None\nbest_min_samples = None\nbest_score = -1\n\nfor eps in np.arange(0.1, 1.0, 0.1):  # Adjust the range as needed\n    for min_samples in range(2, 11):  # Adjust the range as needed\n        dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n        labels = dbscan.fit_predict(X)\n        if len(set(labels)) &gt; 1:  # Ensure more than one cluster is formed\n            score = silhouette_score(X, labels)\n            if score &gt; best_score:\n                best_score = score\n                best_eps = eps\n                best_min_samples = min_samples\n\nprint(f\"Best eps: {best_eps}, Best min_samples: {best_min_samples}, Best Silhouette Score: {best_score}\")\n\nBest eps: 0.2, Best min_samples: 9, Best Silhouette Score: 0.6160671083676901\n\n\n\nfrom sklearn.cluster import DBSCAN\n\n# Initialize DBSCAN\ndbscan = DBSCAN(eps=0.2, min_samples=2)\n\n# Fit DBSCAN on the PCA-transformed data\ncluster_labels = dbscan.fit_predict(batter)\n\n\npl.scatter(batter[:, 0], batter[:, 1], c=cluster_labels, cmap='viridis')\npl.xlabel('Principal Component 1')\npl.ylabel('Principal Component 2')\npl.title('DBSCAN Clustering Results')\npl.show()\n\n\n\n\n\n# Assuming 'player' contains the player names and 'cluster_labels' contains the cluster assignments\n# Create a new DataFrame to combine the results\nnew_batsman = pd.DataFrame({'x': batter[:, 0], 'y': batter[:, 1], 'cluster': cluster_labels, 'player': player})\n\n# Display the resulting DataFrame\nnew_batsman\n\n\n\n\n\n\n\n\nx\ny\ncluster\nplayer\n\n\n\n\n0\n1.036954\n-0.269941\n0\nRT Ponting\n\n\n1\n1.120627\n-0.212675\n0\nJH Kallis\n\n\n2\n0.972643\n-0.241727\n0\nR Dravid\n\n\n3\n0.812778\n-0.326137\n0\nAN Cook\n\n\n4\n1.001332\n-0.113314\n0\nKC Sangakkara\n\n\n...\n...\n...\n...\n...\n\n\n306\n-0.176117\n0.180304\n0\nCJL Rogers\n\n\n307\n-0.373469\n-0.113454\n0\nKOA Powell\n\n\n308\n-0.289984\n0.007711\n0\nAC Hudson\n\n\n309\n-0.265168\n0.025755\n0\nKL Rahul\n\n\n310\n-0.215798\n0.112891\n0\nDN Sardesai\n\n\n\n\n311 rows × 4 columns\n\n\n\n\n# Create a scatter plot with cluster labels\npl.figure(figsize=(10, 6))\nax = sns.scatterplot(x=\"x\", y=\"y\", hue=\"cluster\", data=new_batsman, palette=\"viridis\", s=100)\n\n# Add labels for individual data points\nfor x, y, player, cluster in zip(new_batsman['x'], new_batsman['y'], new_batsman['player'], new_batsman['cluster']):\n    pl.text(x, y, player, fontsize=10, alpha=0.8)\n\n# Set the plot limits and labels\nax.set(ylim=(-3, 3))\npl.xlabel(\"Principal Component 1\", fontsize=15)\npl.ylabel(\"Principal Component 2\", fontsize=15)\n\n# Show the legend\npl.legend(title='Cluster', loc='upper right', labels=[f'Cluster {label}' for label in new_batsman['cluster'].unique()])\n\n# Display the plot\npl.show()\n\n\n\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Set the style\nsns.set(style=\"white\")\n\n# Normalize the \"average\" values\nscaler = MinMaxScaler()\nbatsman['avg_normalized'] = scaler.fit_transform(batsman[['avg']])\n\n# Create a scatter plot with cluster labels and manually set marker size based on \"average\" values\nplt.figure(figsize=(10, 6))\nax = sns.scatterplot(x=\"x\", y=\"y\", hue=\"cluster\", data=new_batsman, palette=\"viridis\", sizes=(50, 500), size=batsman['avg_normalized'])\n\n# Add labels for individual data points\nfor x, y, player, cluster in zip(new_batsman['x'], new_batsman['y'], new_batsman['player'], new_batsman['cluster']):\n    plt.text(x, y, player, fontsize=10, alpha=0.8)\n\n# Set the plot limits and labels\nax.set(ylim=(-3, 3))\nplt.xlabel(\"Principal Component 1\", fontsize=15)\nplt.ylabel(\"Principal Component 2\", fontsize=15)\n\n# Show the legend\nplt.legend(title='Cluster', loc='best', labels=[f'Cluster {label}' for label in new_batsman['cluster'].unique()])\n\n# Display the plot\nplt.show()\n\n\n\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Set the style\nsns.set(style=\"white\")\n\n# Normalize the \"average\" values\nscaler = MinMaxScaler()\nbatsman['100_normalized'] = scaler.fit_transform(batsman[['100']])\n\n# Create a scatter plot with cluster labels and manually set marker size based on \"average\" values\nplt.figure(figsize=(10, 6))\nax = sns.scatterplot(x=\"x\", y=\"y\", hue=\"cluster\", data=new_batsman, palette=\"viridis\", sizes=(50, 500), size=batsman['100_normalized'])\n\n# Add labels for individual data points\nfor x, y, player, cluster in zip(new_batsman['x'], new_batsman['y'], new_batsman['player'], new_batsman['cluster']):\n    plt.text(x, y, player, fontsize=10, alpha=0.8)\n\n# Set the plot limits and labels\nax.set(ylim=(-3, 3))\nplt.xlabel(\"Principal Component 1\", fontsize=15)\nplt.ylabel(\"Principal Component 2\", fontsize=15)\n\n# Show the legend\nplt.legend(title='Cluster', loc='upper right', labels=[f'Cluster {label}' for label in new_batsman['cluster'].unique()])\n\n# Display the plot\nplt.show()"
  }
]