{
  "hash": "247ff921994a4899f1799a246178d9d1",
  "result": {
    "markdown": "---\ntitle: \"Clustering\"\nauthor: \"Mehran Islam\"\ndate: \"2023-12-07\"\ncategories: [code, analysis]\nimage: \"cluster.jpg\"\n---\n\nImporting libraries\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n```\n:::\n\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\ndata=pd.read_csv('air_quality_data.csv')\ndata.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>State</th>\n      <th>County</th>\n      <th>Year</th>\n      <th>Days with AQI</th>\n      <th>Good Days</th>\n      <th>Moderate Days</th>\n      <th>Unhealthy for Sensitive Groups Days</th>\n      <th>Unhealthy Days</th>\n      <th>Very Unhealthy Days</th>\n      <th>Hazardous Days</th>\n      <th>Max AQI</th>\n      <th>90th Percentile AQI</th>\n      <th>Median AQI</th>\n      <th>Days CO</th>\n      <th>Days NO2</th>\n      <th>Days Ozone</th>\n      <th>Days PM2.5</th>\n      <th>Days PM10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Alabama</td>\n      <td>Baldwin</td>\n      <td>2022</td>\n      <td>141</td>\n      <td>119</td>\n      <td>22</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>96</td>\n      <td>52</td>\n      <td>40</td>\n      <td>0</td>\n      <td>0</td>\n      <td>114</td>\n      <td>27</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Alabama</td>\n      <td>Clay</td>\n      <td>2022</td>\n      <td>58</td>\n      <td>50</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>64</td>\n      <td>52</td>\n      <td>27</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>58</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Alabama</td>\n      <td>DeKalb</td>\n      <td>2022</td>\n      <td>242</td>\n      <td>225</td>\n      <td>17</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>97</td>\n      <td>48</td>\n      <td>37</td>\n      <td>0</td>\n      <td>0</td>\n      <td>224</td>\n      <td>18</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Alabama</td>\n      <td>Elmore</td>\n      <td>2022</td>\n      <td>117</td>\n      <td>110</td>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>67</td>\n      <td>47</td>\n      <td>37</td>\n      <td>0</td>\n      <td>0</td>\n      <td>117</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Alabama</td>\n      <td>Etowah</td>\n      <td>2022</td>\n      <td>179</td>\n      <td>140</td>\n      <td>39</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>93</td>\n      <td>58</td>\n      <td>42</td>\n      <td>0</td>\n      <td>0</td>\n      <td>76</td>\n      <td>103</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\ndata.apply(pd.isnull).sum()/data.shape[0]\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\nState                                  0.0\nCounty                                 0.0\nYear                                   0.0\nDays with AQI                          0.0\nGood Days                              0.0\nModerate Days                          0.0\nUnhealthy for Sensitive Groups Days    0.0\nUnhealthy Days                         0.0\nVery Unhealthy Days                    0.0\nHazardous Days                         0.0\nMax AQI                                0.0\n90th Percentile AQI                    0.0\nMedian AQI                             0.0\nDays CO                                0.0\nDays NO2                               0.0\nDays Ozone                             0.0\nDays PM2.5                             0.0\nDays PM10                              0.0\ndtype: float64\n```\n:::\n:::\n\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\ndata.describe()\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>Days with AQI</th>\n      <th>Good Days</th>\n      <th>Moderate Days</th>\n      <th>Unhealthy for Sensitive Groups Days</th>\n      <th>Unhealthy Days</th>\n      <th>Very Unhealthy Days</th>\n      <th>Hazardous Days</th>\n      <th>Max AQI</th>\n      <th>90th Percentile AQI</th>\n      <th>Median AQI</th>\n      <th>Days CO</th>\n      <th>Days NO2</th>\n      <th>Days Ozone</th>\n      <th>Days PM2.5</th>\n      <th>Days PM10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>966.0</td>\n      <td>966.000000</td>\n      <td>966.000000</td>\n      <td>966.000000</td>\n      <td>966.000000</td>\n      <td>966.000000</td>\n      <td>966.000000</td>\n      <td>966.000000</td>\n      <td>966.000000</td>\n      <td>966.000000</td>\n      <td>966.000000</td>\n      <td>966.000000</td>\n      <td>966.000000</td>\n      <td>966.000000</td>\n      <td>966.000000</td>\n      <td>966.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2022.0</td>\n      <td>208.917184</td>\n      <td>173.689441</td>\n      <td>33.388199</td>\n      <td>1.566253</td>\n      <td>0.214286</td>\n      <td>0.026915</td>\n      <td>0.032091</td>\n      <td>112.774327</td>\n      <td>55.115942</td>\n      <td>36.821946</td>\n      <td>0.666667</td>\n      <td>4.330228</td>\n      <td>127.083851</td>\n      <td>68.909938</td>\n      <td>7.926501</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.0</td>\n      <td>58.371700</td>\n      <td>52.564146</td>\n      <td>29.654791</td>\n      <td>4.591190</td>\n      <td>1.401200</td>\n      <td>0.267981</td>\n      <td>0.419727</td>\n      <td>254.401084</td>\n      <td>14.632954</td>\n      <td>9.672426</td>\n      <td>5.107616</td>\n      <td>19.372906</td>\n      <td>82.596442</td>\n      <td>69.893621</td>\n      <td>30.194461</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>2022.0</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>8.000000</td>\n      <td>5.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2022.0</td>\n      <td>181.000000</td>\n      <td>147.250000</td>\n      <td>12.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>77.000000</td>\n      <td>48.000000</td>\n      <td>35.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>76.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2022.0</td>\n      <td>212.000000</td>\n      <td>174.000000</td>\n      <td>24.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>95.000000</td>\n      <td>54.000000</td>\n      <td>39.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>131.500000</td>\n      <td>58.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2022.0</td>\n      <td>261.750000</td>\n      <td>213.000000</td>\n      <td>46.750000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>115.000000</td>\n      <td>61.000000</td>\n      <td>42.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>188.000000</td>\n      <td>107.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2022.0</td>\n      <td>306.000000</td>\n      <td>293.000000</td>\n      <td>197.000000</td>\n      <td>57.000000</td>\n      <td>20.000000</td>\n      <td>6.000000</td>\n      <td>10.000000</td>\n      <td>7577.000000</td>\n      <td>151.000000</td>\n      <td>77.000000</td>\n      <td>77.000000</td>\n      <td>209.000000</td>\n      <td>299.000000</td>\n      <td>303.000000</td>\n      <td>299.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nair=data[[\"State\",\"County\",\"Max AQI\",\"90th Percentile AQI\",\"Days PM2.5\"]].copy()\nair.columns=[\"State\",\"County\",\"Max AQI\",\"90th Percentile AQI\",\"Days PM2.5\"]\nair.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>State</th>\n      <th>County</th>\n      <th>Max AQI</th>\n      <th>90th Percentile AQI</th>\n      <th>Days PM2.5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Alabama</td>\n      <td>Baldwin</td>\n      <td>96</td>\n      <td>52</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Alabama</td>\n      <td>Clay</td>\n      <td>64</td>\n      <td>52</td>\n      <td>58</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Alabama</td>\n      <td>DeKalb</td>\n      <td>97</td>\n      <td>48</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Alabama</td>\n      <td>Elmore</td>\n      <td>67</td>\n      <td>47</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Alabama</td>\n      <td>Etowah</td>\n      <td>93</td>\n      <td>58</td>\n      <td>103</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\n#to save these features for the future\nState = air['State'].tolist()\nCounty = air['County'].tolist()\n```\n:::\n\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\n#sns.pairplot(air)\n#plt.show()\n```\n:::\n\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nair = pd.DataFrame(air)\n\n# Drop the \"State\" and \"County\" columns\nair = air.drop(columns=[\"State\", \"County\"])\n```\n:::\n\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Initialize the Min-Max scaler\nscaler = MinMaxScaler()\n\n# Fit and transform the entire \"air\" dataset\nair = scaler.fit_transform(air)\n\n# \"normalized_air\" now contains the scaled features in the [0, 1] range\nair\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\narray([[0.01162637, 0.32191781, 0.08910891],\n       [0.0073986 , 0.32191781, 0.19141914],\n       [0.01175849, 0.29452055, 0.05940594],\n       ...,\n       [0.01215484, 0.29452055, 0.00660066],\n       [0.00620954, 0.08219178, 0.        ],\n       [0.00660589, 0.26712329, 0.        ]])\n```\n:::\n:::\n\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nfrom sklearn.decomposition import PCA\n\n# Initialize PCA with the desired number of components (e.g., 2 for a 2D visualization)\nnum_components = 2\npca = PCA(n_components=num_components)\n\n# Fit and transform your normalized data with PCA\nnew_air = pca.fit_transform(air)\n```\n:::\n\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nfrom sklearn.neighbors import NearestNeighbors\n\n# Assuming you have normalized your data and stored it in 'normalized_air'\n\n# Determine the number of nearest neighbors (k) for the k-distance plot\nk = 5  # You can adjust this value\n\n# Fit a Nearest Neighbors model to the normalized data\nnn_model = NearestNeighbors(n_neighbors=k)\nnn_model.fit(air)\n\n# Calculate distances to the k-th nearest neighbor for each data point\ndistances, _ = nn_model.kneighbors(air)\n\n# Sort the distances and create a k-distance plot\nsorted_distances = np.sort(distances[:, -1])  # Sort by the distance to the k-th neighbor\nplt.plot(np.arange(1, len(sorted_distances) + 1), sorted_distances)\nplt.xlabel(\"Data Point Index\")\nplt.ylabel(f\"Distance to {k}-th Nearest Neighbor\")\nplt.title(f\"{k}-Distance Plot\")\nplt.grid(True)\n\n# Display the plot\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-12-output-1.png){width=599 height=449}\n:::\n:::\n\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.metrics import silhouette_score\n\n\n# Your data\nX = new_air  # Your data points\n\nbest_eps = None\nbest_min_samples = None\nbest_score = -1\n\nfor eps in np.arange(0.1, 1.0, 0.1):  # Adjust the range as needed\n    for min_samples in range(2, 20):  # Adjust the range as needed\n        dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n        labels = dbscan.fit_predict(X)\n        if len(set(labels)) > 1:  # Ensure more than one cluster is formed\n            score = silhouette_score(X, labels)\n            if score > best_score:\n                best_score = score\n                best_eps = eps\n                best_min_samples = min_samples\n\nprint(f\"Best eps: {best_eps}, Best min_samples: {best_min_samples}, Best Silhouette Score: {best_score}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBest eps: 0.2, Best min_samples: 10, Best Silhouette Score: 0.5989772983728644\n```\n:::\n:::\n\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nfrom sklearn.cluster import DBSCAN\n\n# Initialize the DBSCAN model with your chosen parameters\ndbscan = DBSCAN(eps=0.05, min_samples=5)\n\n# Fit the model to the PCA-transformed data\ndbscan.fit(new_air)\n\n# Access the cluster labels assigned to each data point\ncluster_labels = dbscan.labels_\n\n\n\n# Plot the clusters using the first two principal components\nplt.figure(figsize=(10, 6))\nplt.scatter(new_air[:, 0], new_air[:, 1], c=cluster_labels, cmap='viridis')\nplt.xlabel(\"Principal Component 1\")\nplt.ylabel(\"Principal Component 2\")\nplt.title(\"DBSCAN Clustering Results after PCA\")\nplt.colorbar()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-14-output-1.png){width=763 height=523}\n:::\n:::\n\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\n# Assuming you have cluster labels and PCA-transformed data\n# Create a DataFrame that includes the cluster labels\ndata_with_clusters = pd.DataFrame({\n    'Cluster': cluster_labels,\n    'PCA Component 1': new_air[:, 0],\n    'PCA Component 2': new_air[:, 1]\n})\n\n# Create a box plot for PCA Component 1 by cluster\nplt.figure(figsize=(12, 6))\nsns.boxplot(x='Cluster', y='PCA Component 1', data=data_with_clusters)\nplt.xlabel('Cluster')\nplt.ylabel('PCA Component 1')\nplt.title('Box Plot of PCA Component 1 by Cluster')\nplt.show()\n\n# Create a box plot for PCA Component 2 by cluster\nplt.figure(figsize=(12, 6))\nsns.boxplot(x='Cluster', y='PCA Component 2', data=data_with_clusters)\nplt.xlabel('Cluster')\nplt.ylabel('PCA Component 2')\nplt.title('Box Plot of PCA Component 2 by Cluster')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-15-output-1.png){width=972 height=523}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-15-output-2.png){width=972 height=523}\n:::\n:::\n\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\n# Create a new DataFrame to combine the results\nnew_air = pd.DataFrame({'x': new_air[:, 0], 'y': new_air[:, 1], 'Cluster': cluster_labels, 'State': State})\n\n# Display the resulting DataFrame\nnew_air\n```\n\n::: {.cell-output .cell-output-display execution_count=15}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x</th>\n      <th>y</th>\n      <th>Cluster</th>\n      <th>State</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.138111</td>\n      <td>-0.022733</td>\n      <td>0</td>\n      <td>Alabama</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.035805</td>\n      <td>-0.022062</td>\n      <td>0</td>\n      <td>Alabama</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.167556</td>\n      <td>-0.050336</td>\n      <td>0</td>\n      <td>Alabama</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.226895</td>\n      <td>-0.057990</td>\n      <td>0</td>\n      <td>Alabama</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.112319</td>\n      <td>0.020583</td>\n      <td>0</td>\n      <td>Alabama</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>961</th>\n      <td>-0.224044</td>\n      <td>-0.009787</td>\n      <td>0</td>\n      <td>Wyoming</td>\n    </tr>\n    <tr>\n      <th>962</th>\n      <td>-0.125231</td>\n      <td>0.012099</td>\n      <td>0</td>\n      <td>Wyoming</td>\n    </tr>\n    <tr>\n      <th>963</th>\n      <td>-0.220359</td>\n      <td>-0.050802</td>\n      <td>0</td>\n      <td>Wyoming</td>\n    </tr>\n    <tr>\n      <th>964</th>\n      <td>-0.224973</td>\n      <td>-0.263103</td>\n      <td>0</td>\n      <td>Wyoming</td>\n    </tr>\n    <tr>\n      <th>965</th>\n      <td>-0.226703</td>\n      <td>-0.078571</td>\n      <td>0</td>\n      <td>Wyoming</td>\n    </tr>\n  </tbody>\n</table>\n<p>966 rows Ã— 4 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Assuming you have cluster labels, PCA-transformed data, and State information\n# Create a DataFrame that includes cluster labels, PCA components, and State\ndata_with_clusters = pd.DataFrame({\n    'Cluster': cluster_labels,\n    'PCA Component 1': new_air['x'],  # Assuming 'x' represents PCA Component 1\n    'PCA Component 2': new_air['y'],  # Assuming 'y' represents PCA Component 2\n    'State': State  # Assuming 'State' is available in your data\n})\n\n# Get unique cluster labels\nunique_clusters = data_with_clusters['Cluster'].unique()\n\n# Iterate through clusters and create individual scatter plots\nfor cluster in unique_clusters:\n    plt.figure(figsize=(10, 6))\n    ax = sns.scatterplot(\n        x=\"PCA Component 1\",\n        y=\"PCA Component 2\",\n        data=data_with_clusters[data_with_clusters['Cluster'] == cluster],  # Filter data by cluster\n        palette=\"viridis\",\n        s=100,\n    )\n\n    # Add labels for individual data points\n    for x, y, state in zip(\n        data_with_clusters[data_with_clusters['Cluster'] == cluster]['PCA Component 1'],\n        data_with_clusters[data_with_clusters['Cluster'] == cluster]['PCA Component 2'],\n        data_with_clusters[data_with_clusters['Cluster'] == cluster]['State'],\n    ):\n        plt.text(x, y, state, fontsize=10, alpha=0.8)\n\n    # Set the plot limits and labels\n    ax.set(ylim=(-3, 3))\n    plt.xlabel(\"Principal Component 1\", fontsize=15)\n    plt.ylabel(\"Principal Component 2\", fontsize=15)\n\n    # Set the title for the individual cluster plot\n    plt.title(f'Scatter Plot for Cluster {cluster}', fontsize=15)\n\n    # Display the plot\n    plt.show()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nC:\\Users\\mehra\\AppData\\Local\\Temp\\ipykernel_50908\\1173522113.py:19: UserWarning:\n\nIgnoring `palette` because no `hue` variable has been assigned.\n\nC:\\Users\\mehra\\AppData\\Local\\Temp\\ipykernel_50908\\1173522113.py:19: UserWarning:\n\nIgnoring `palette` because no `hue` variable has been assigned.\n\nC:\\Users\\mehra\\AppData\\Local\\Temp\\ipykernel_50908\\1173522113.py:19: UserWarning:\n\nIgnoring `palette` because no `hue` variable has been assigned.\n\nC:\\Users\\mehra\\AppData\\Local\\Temp\\ipykernel_50908\\1173522113.py:19: UserWarning:\n\nIgnoring `palette` because no `hue` variable has been assigned.\n\nC:\\Users\\mehra\\AppData\\Local\\Temp\\ipykernel_50908\\1173522113.py:19: UserWarning:\n\nIgnoring `palette` because no `hue` variable has been assigned.\n\nC:\\Users\\mehra\\AppData\\Local\\Temp\\ipykernel_50908\\1173522113.py:19: UserWarning:\n\nIgnoring `palette` because no `hue` variable has been assigned.\n\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-17-output-2.png){width=846 height=534}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-17-output-3.png){width=862 height=534}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-17-output-4.png){width=886 height=534}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-17-output-5.png){width=845 height=534}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-17-output-6.png){width=818 height=534}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-17-output-7.png){width=855 height=534}\n:::\n:::\n\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\n# Assuming you have cluster labels, PCA-transformed data, and State information\n# Create a DataFrame that includes cluster labels, PCA components, and State\ndata_with_clusters = pd.DataFrame({\n    'Cluster': cluster_labels,\n    'PCA Component 1': new_air['x'],  # Assuming 'x' represents PCA Component 1\n    'PCA Component 2': new_air['y'],  # Assuming 'y' represents PCA Component 2\n    'State': State  # Assuming 'State' is available in your data\n})\n\n# Get unique cluster labels\nunique_clusters = data_with_clusters['Cluster'].unique()\n\n# Iterate through clusters and create individual bar plots for the 'State' variable\nfor cluster in unique_clusters:\n    plt.figure(figsize=(10, 6))\n    \n    # Count the occurrences of each 'State' within the cluster\n    state_counts = data_with_clusters[data_with_clusters['Cluster'] == cluster]['State'].value_counts()\n    \n    # Create a bar plot for the 'State' variable within the cluster\n    state_counts.plot(kind='bar', color='teal')\n    \n    plt.xlabel(\"State\", fontsize=15)\n    plt.ylabel(\"Count\", fontsize=15)\n    plt.title(f'Bar Plot for States in Cluster {cluster}', fontsize=15)\n    \n    plt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-18-output-1.png){width=815 height=656}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-18-output-2.png){width=828 height=599}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-18-output-3.png){width=815 height=644}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-18-output-4.png){width=815 height=619}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-18-output-5.png){width=819 height=584}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-18-output-6.png){width=828 height=619}\n:::\n:::\n\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\nfrom sklearn.metrics import silhouette_samples, silhouette_score\n\n# Compute silhouette scores for each data point\nsilhouette_avg = silhouette_score(new_air[['x', 'y']], cluster_labels)\nsample_silhouette_values = silhouette_samples(new_air[['x', 'y']], cluster_labels)\n\n# Add silhouette scores to the DataFrame\nnew_air['Silhouette Score'] = sample_silhouette_values\n\nprint(f\"Silhouette Score: {silhouette_avg}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSilhouette Score: 0.14829996909282617\n```\n:::\n:::\n\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\nimport numpy as np\n\n# Create a bar plot to visualize the silhouette scores by cluster\nplt.figure(figsize=(10, 6))\nax = sns.barplot(x=cluster_labels, y=new_air['Silhouette Score'], palette=\"viridis\")\nplt.xlabel(\"Cluster\", fontsize=15)\nplt.ylabel(\"Silhouette Score\", fontsize=15)\nplt.title(\"Silhouette Scores by Cluster\", fontsize=15)\n\n# Draw a vertical line at the average silhouette score\nplt.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\", label=\"Average Silhouette Score\")\nplt.legend()\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-20-output-1.png){width=830 height=534}\n:::\n:::\n\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\n#Max AQI (Maximum Air Quality Index): Clusters could represent groups of states with similar maximum air quality values. For example, a cluster might contain states that frequently experience high maximum AQI values, indicating occasional poor air quality.\n\n#90th Percentile AQI: This feature reflects the 90th percentile of AQI values, which indicates the AQI level exceeded only 10% of the time. Clusters might group states with similar patterns of exceeding AQI levels.\n\n#Days PM2.5, Days Ozone, Days CO: These features represent the number of days when specific air pollutants (PM2.5, Ozone, CO) exceed certain thresholds. Clusters could represent states with similar distributions of days exceeding these thresholds.\n```\n:::\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}