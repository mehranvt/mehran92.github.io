{
  "hash": "c8172d7f5ed6710626cbc65e643f1212",
  "result": {
    "markdown": "---\ntitle: \"Regression\"\nauthor: \"Mehran Islam\"\ndate: \"2023-12-07\"\ncategories: [code, analysis]\nimage: \"regression.jpg\"\n---\n\nThis is a post that looks at linear and non-linear regression.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\n#importing the needed libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n```\n:::\n\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n#importing the dataset\ndata=pd.read_csv('insurance.csv',sep=',')\ndata.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=20}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>bmi</th>\n      <th>children</th>\n      <th>smoker</th>\n      <th>region</th>\n      <th>charges</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>19</td>\n      <td>female</td>\n      <td>27.900</td>\n      <td>0</td>\n      <td>yes</td>\n      <td>southwest</td>\n      <td>16884.92400</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>18</td>\n      <td>male</td>\n      <td>33.770</td>\n      <td>1</td>\n      <td>no</td>\n      <td>southeast</td>\n      <td>1725.55230</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>28</td>\n      <td>male</td>\n      <td>33.000</td>\n      <td>3</td>\n      <td>no</td>\n      <td>southeast</td>\n      <td>4449.46200</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>33</td>\n      <td>male</td>\n      <td>22.705</td>\n      <td>0</td>\n      <td>no</td>\n      <td>northwest</td>\n      <td>21984.47061</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>32</td>\n      <td>male</td>\n      <td>28.880</td>\n      <td>0</td>\n      <td>no</td>\n      <td>northwest</td>\n      <td>3866.85520</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\ninsurance=data[['age','bmi','children','charges']].copy()\ninsurance.columns=['age','bmi','no_of_children','cost']\ninsurance.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=21}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>bmi</th>\n      <th>no_of_children</th>\n      <th>cost</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>19</td>\n      <td>27.900</td>\n      <td>0</td>\n      <td>16884.92400</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>18</td>\n      <td>33.770</td>\n      <td>1</td>\n      <td>1725.55230</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>28</td>\n      <td>33.000</td>\n      <td>3</td>\n      <td>4449.46200</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>33</td>\n      <td>22.705</td>\n      <td>0</td>\n      <td>21984.47061</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>32</td>\n      <td>28.880</td>\n      <td>0</td>\n      <td>3866.85520</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nsns.lmplot(x='bmi',y='cost',data=insurance)\nplt.xlabel('BMI')\nplt.ylabel('Insurance cost')\nplt.title('Cost Vs BMI');\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nC:\\Users\\mehra\\anaconda3\\Lib\\site-packages\\seaborn\\axisgrid.py:118: UserWarning:\n\nThe figure layout has changed to tight\n\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-5-output-2.png){width=469 height=488}\n:::\n:::\n\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\n#checking the missing value\ninsurance.apply(pd.isnull).sum()\n```\n\n::: {.cell-output .cell-output-display execution_count=23}\n```\nage               0\nbmi               0\nno_of_children    0\ncost              0\ndtype: int64\n```\n:::\n:::\n\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\n#let's see the correlation plot to identify how related are the features so that we know which features are important\n# correlation plot\ninsurance = insurance.corr()\nsns.heatmap(insurance, cmap = 'summer', annot= True);\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-7-output-1.png){width=533 height=416}\n:::\n:::\n\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\n# so we can see that there is no co-relation between the features,so let's check the pair plots\nsns.pairplot(insurance)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nC:\\Users\\mehra\\anaconda3\\Lib\\site-packages\\seaborn\\axisgrid.py:118: UserWarning:\n\nThe figure layout has changed to tight\n\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-8-output-2.png){width=949 height=945}\n:::\n:::\n\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\n# now let's preapare our data to be machine learning ready\n#let's first do one-hot encoding\nfeatures_to_select=['sex','children', 'smoker', 'region']\n\ninsurance_encoded = pd.get_dummies(data = data, prefix = 'encoded', prefix_sep='_',\n               columns = features_to_select,\n               drop_first =True,\n              dtype='int8')\n```\n:::\n\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\ninsurance_encoded\n```\n\n::: {.cell-output .cell-output-display execution_count=27}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>bmi</th>\n      <th>charges</th>\n      <th>encoded_male</th>\n      <th>encoded_1</th>\n      <th>encoded_2</th>\n      <th>encoded_3</th>\n      <th>encoded_4</th>\n      <th>encoded_5</th>\n      <th>encoded_yes</th>\n      <th>encoded_northwest</th>\n      <th>encoded_southeast</th>\n      <th>encoded_southwest</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>19</td>\n      <td>27.900</td>\n      <td>16884.92400</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>18</td>\n      <td>33.770</td>\n      <td>1725.55230</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>28</td>\n      <td>33.000</td>\n      <td>4449.46200</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>33</td>\n      <td>22.705</td>\n      <td>21984.47061</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>32</td>\n      <td>28.880</td>\n      <td>3866.85520</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1333</th>\n      <td>50</td>\n      <td>30.970</td>\n      <td>10600.54830</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1334</th>\n      <td>18</td>\n      <td>31.920</td>\n      <td>2205.98080</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1335</th>\n      <td>18</td>\n      <td>36.850</td>\n      <td>1629.83350</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1336</th>\n      <td>21</td>\n      <td>25.800</td>\n      <td>2007.94500</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1337</th>\n      <td>61</td>\n      <td>29.070</td>\n      <td>29141.36030</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1338 rows Ã— 13 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\ninsurance_encoded['charges'] = np.log(insurance_encoded['charges'])\n```\n:::\n\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\n#let's now train our data\n\nfrom sklearn.model_selection import train_test_split\n\nX = insurance_encoded.drop('charges',axis=1) \ny = insurance_encoded['charges']\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=23)\n```\n:::\n\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\n#now let's perform a linear regression model:\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Initialize the Linear Regression model\nlinear_model = LinearRegression()\n\n# Fit the model on the training data\nlinear_model.fit(X_train, y_train)\n\n# Make predictions on the test data\ny_pred_linear = linear_model.predict(X_test)\n\n# Evaluate the model\nmse_linear = mean_squared_error(y_test, y_pred_linear)\nr2_linear = r2_score(y_test, y_pred_linear)\n\nprint(\"Linear Regression Results:\")\nprint(f\"Mean Squared Error: {mse_linear}\")\nprint(f\"R-squared: {r2_linear}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear Regression Results:\nMean Squared Error: 0.18729622322981895\nR-squared: 0.7795687545055319\n```\n:::\n:::\n\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\n#I want to check either linear or non-linear model is best for this data so I also want to perform a non-linear regression model:\n\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import make_pipeline\n\n# Choose the degree of the polynomial\ndegree = 2  # You can experiment with different degrees\n\n# Create a polynomial regression model\npoly_model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n\n# Fit the model on the training data\npoly_model.fit(X_train, y_train)\n\n# Make predictions on the test data\ny_pred_poly = poly_model.predict(X_test)\n\n# Evaluate the model\nmse_poly = mean_squared_error(y_test, y_pred_poly)\nr2_poly = r2_score(y_test, y_pred_poly)\n\nprint(\"\\nPolynomial Regression Results:\")\nprint(f\"Mean Squared Error: {mse_poly}\")\nprint(f\"R-squared: {r2_poly}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nPolynomial Regression Results:\nMean Squared Error: 0.12727884942567\nR-squared: 0.8502039452788253\n```\n:::\n:::\n\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\n#Let's try to visualize both of them:\n\n#For the linear regression data visualizsation:\n\n# Plotting Linear Regression\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nsns.scatterplot(x=y_test, y=y_pred_linear)\nplt.title(\"Linear Regression: Actual vs Predicted Charges\")\nplt.xlabel(\"Actual Charges\")\nplt.ylabel(\"Predicted Charges\")\n```\n\n::: {.cell-output .cell-output-display execution_count=32}\n```\nText(0, 0.5, 'Predicted Charges')\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-15-output-2.png){width=494 height=523}\n:::\n:::\n\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\n# Plotting Polynomial Regression\nplt.subplot(1, 2, 2)\nsns.scatterplot(x=y_test, y=y_pred_poly)\nplt.title(\"Polynomial Regression: Actual vs Predicted Charges\")\nplt.xlabel(\"Actual Charges\")\nplt.ylabel(\"Predicted Charges\")\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-16-output-1.png){width=433 height=468}\n:::\n:::\n\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\n#In this case, the polynomial regression has a lower MSE and a higher R-squared,\n# which indicates it fits the data better and explains more of the variance.\n```\n:::\n\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\n# Accessing coefficients for Polynomial Regression\npoly_coefficients = poly_model.named_steps['linearregression'].coef_\n\n# Creating a DataFrame to display coefficients along with feature names\npoly_coefficients_df = pd.DataFrame({\n    'Feature': X_train.columns,\n    'Coefficient': poly_coefficients[:len(X_train.columns)]  # Only take coefficients corresponding to original features\n})\n\n# Displaying the coefficients\nprint(poly_coefficients_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              Feature   Coefficient\n0                 age  1.023352e-13\n1                 bmi  4.964836e-02\n2        encoded_male  5.215860e-02\n3           encoded_1 -1.934427e-01\n4           encoded_2  1.974225e-01\n5           encoded_3  5.101884e-01\n6           encoded_4  4.195310e-01\n7           encoded_5  3.787017e-01\n8         encoded_yes  3.949445e-01\n9   encoded_northwest  6.499769e-01\n10  encoded_southeast -2.585821e-02\n11  encoded_southwest -4.188016e-02\n```\n:::\n:::\n\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\n# Accessing coefficients for Polynomial Regression\npoly_coefficients = poly_model.named_steps['linearregression'].coef_\n\n# Creating a DataFrame to display coefficients along with feature names\npoly_coefficients_df = pd.DataFrame({\n    'Feature': X_train.columns,\n    'Coefficient': poly_coefficients[:len(X_train.columns)]  # Only take coefficients corresponding to original features\n})\n\n# Sort coefficients by absolute value for better visualization\npoly_coefficients_df = poly_coefficients_df.reindex(\n    poly_coefficients_df['Coefficient'].abs().sort_values(ascending=False).index\n)\n\n# Create a bar plot\nplt.figure(figsize=(10, 6))\nsns.barplot(x='Coefficient', y='Feature', data=poly_coefficients_df, palette='viridis')\nplt.title('Polynomial Regression Coefficients')\nplt.xlabel('Coefficient Value')\nplt.ylabel('Feature')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-19-output-1.png){width=924 height=523}\n:::\n:::\n\n\n#Age: The coefficient is very close to zero, suggesting that age has a minimal impact on the predicted charges.\n\n#BMI: The coefficient is positive, indicating that an increase in BMI is associated with higher predicted charges.\n\n#Gender (encoded_male): The coefficient is positive, suggesting that being male is associated with higher predicted charges compared to being female.\n\n#Children (encoded_1, encoded_2, encoded_3, encoded_4, encoded_5): These coefficients are negative, indicating that having more children is associated with lower predicted charges.\n\n#Smoker (encoded_yes): The coefficient is positive suggesting that being a smoker is strongly associated with higher predicted charges.\n\n#Region (encoded_northwest, encoded_southeast, encoded_southwest): These coefficients are positive, with the highest coefficient for 'encoded_northwest' indicating that individuals from the northwest region tend to have higher predicted charges.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}